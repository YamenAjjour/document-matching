{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_goal=\"/mnt/ceph/storage/data-in-progress/data-research/arguana/args/args-near-duplicates-mapper/anserini-indices/version-1.0-cleaned.jsonl\"\n",
    "path_source=\"/mnt/ceph/storage/data-in-progress/data-research/arguana/args/args-near-duplicates-mapper/anserini-indices/version-2020-04-01.jsonl\"\n",
    "path_similarities=\"/mnt/ceph/storage/.snap/daily_20210804/data-in-progress/data-research/arguana/args/args-near-duplicates-mapper/s3-similarities/s3-scores-for-index-1.0-and-cleaned-2020-04-01.jsonl\"\n",
    "path_judgements=\"/mnt/ceph/storage/data-in-progress/data-research/arguana/args/args-near-duplicates-mapper/beir/touche2020-task1-version-2020-04-01-corrected.qrels\"\n",
    "path_all_score_mappings=\"/mnt/ceph/storage/data-in-progress/data-research/arguana/args/args-near-duplicates-mapper/validation/all-id-mappings.csv\"\n",
    "path_all_url_mappings=\"/mnt/ceph/storage/data-in-progress/data-research/arguana/args/args-near-duplicates-mapper/validation/all-url-mappings.csv\"\n",
    "path_mappings=\"/mnt/ceph/storage/data-in-progress/data-research/arguana/args/args-near-duplicates-mapper/validation/mappings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ijson\n",
    "from trectools import TrecQrel, procedures\n",
    "file_goal = open (path_goal,'r',encoding=\"utf-8\")\n",
    "file_source = open(path_source,'r',encoding=\"utf-8\")\n",
    "qrels = TrecQrel(path_judgements)\n",
    "df_qrels=qrels.qrels_data\n",
    "df_qrels.rename({'docid':'source-id'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-86b1f11dba5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mleft_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mright_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'right'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "i = 0\n",
    "for i,qrel in df_qrels.iterrows():\n",
    "    file_similarities = open(path_similarities,'r',encoding=\"utf-8\")\n",
    "    file_similarities_2 = open(path_similarities,'r',encoding=\"utf-8\")\n",
    "    scores=ijson.items(file_similarities,'s3Score',multiple_values=True)\n",
    "    pairs = ijson.items(file_similarities_2,'idPair',multiple_values=True)\n",
    "    pairs_similarities=[]\n",
    "    b=-1\n",
    "    for pair in pairs:\n",
    "        score = next(scores)\n",
    "        left_id = pair['left']\n",
    "        right_id = pair['right']\n",
    "        if left_id == qrel['source-id']:\n",
    "            pairs_similarities.append((left_id,right_id,score))\n",
    "            b=1\n",
    "            break\n",
    "        if right_id == qrel['source-id']:\n",
    "            pairs_similarities.append((right_id,left_id,score))\n",
    "            b=1\n",
    "            break\n",
    "        if b==1:\n",
    "            break\n",
    "    file_similarities.close()\n",
    "    file_similarities_2.close()\n",
    "print(id_pairs)\n",
    "ids,goal_ids,scores=zip(*id_pairs)\n",
    "df_all_score_mappings=pd.DataFrame({'source-id':ids,'goal-id':goal_ids,'score':scores})\n",
    "df_all_score_mappings.to_csv(path_all_score_mappings,sep=\",\",encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    print(qrel['docid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entry2argument(entry):\n",
    "    conclusion = entry['conclusion'].lower().replace(\"\\t\",\" \")\n",
    "    premise = entry['premises'][0]['text'].lower().replace(\"\\t\",\" \")\n",
    "    argument_id = entry['id']\n",
    "    Argument = namedtuple('Argument', 'id conclusion premise url')\n",
    "    argument_text = conclusion + \" \" + premise\n",
    "    argument_text = clean(argument_text)\n",
    "    if 'sourceUrl' in entry['context']:\n",
    "        url = entry['context']['sourceUrl']\n",
    "    else:\n",
    "        url=None\n",
    "    return Argument(argument_id,conclusion,premise,hash,url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_id_url_map(json_file,id_column):\n",
    "    arguments= ijson.items(json_file,'arguments.item')\n",
    "    parsed_arguments= [entry2argument(argument) for argument in arguments]\n",
    "    ids=[parsed_argument.id for parsed_argument in all_parsed_arguments]\n",
    "    urls=[parsed_argument.url for parsed_argument in all_parsed_arguments]\n",
    "    df=pd.DataFrame({id_column:ids,'url':urls})\n",
    "    return df\n",
    "\n",
    "df_source_url=get_id_url_map(file_source,'source-id')\n",
    "df_source_url=df_source_url.merge(df_qrels,on='source-id')\n",
    "df_goal_url=get_id_url_map(file_goal,'goal-id')\n",
    "df_url_mappings=df_source_url.merge(df_goal_url,on='url')\n",
    "df_url_mappings.to_csv(path_all_url_mappings,sep=\",\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_score_mappings=pd.read_csv(path_all_score_mappings,sep=\",\",encoding=\"utf-8\")\n",
    "df_mappings=df_all_score_mappings.merge(df_url_mappings,on=['source-id','goal-id'])\n",
    "df_mappings.to_csv(path_mappings,sep=\",\",encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
